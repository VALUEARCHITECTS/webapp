name: Daily Database Backup

on:
  schedule:
    # æ¯Žæ—¥æ·±å¤œ2:00 JSTï¼ˆUTC 17:00å‰æ—¥ï¼‰ã«å®Ÿè¡Œ
    - cron: '0 17 * * *'
  
  # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Wrangler
        run: npm install -g wrangler
      
      - name: Create backup directory
        run: mkdir -p backups
      
      - name: Export database (READ ONLY)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "ðŸ” Starting database backup (READ ONLY operation)..."
          
          # ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆJSTï¼‰
          BACKUP_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)
          BACKUP_FILE="backups/${BACKUP_DATE}.sql"
          
          echo "ðŸ“… Backup date: ${BACKUP_DATE}"
          echo "ðŸ“ Backup file: ${BACKUP_FILE}"
          
          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆREAD ONLYï¼‰
          # ã“ã®ã‚³ãƒžãƒ³ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹ã ã‘ã§ã€å‰Šé™¤ãƒ»å¤‰æ›´ã¯ä¸€åˆ‡è¡Œã„ã¾ã›ã‚“
          wrangler d1 export webapp-production --remote --output="${BACKUP_FILE}"
          
          # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèª
          BACKUP_SIZE=$(ls -lh "${BACKUP_FILE}" | awk '{print $5}')
          echo "âœ… Backup completed: ${BACKUP_SIZE}"
          
          # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®10è¡Œã‚’è¡¨ç¤ºï¼ˆç¢ºèªç”¨ï¼‰
          echo "ðŸ“„ Backup file preview (first 10 lines):"
          head -10 "${BACKUP_FILE}"
      
      - name: Compress backup
        run: |
          BACKUP_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)
          BACKUP_FILE="backups/${BACKUP_DATE}.sql"
          rm -f "${BACKUP_FILE}.gz"
          gzip -k "${BACKUP_FILE}"
          ORIGINAL_SIZE=$(ls -lh "${BACKUP_FILE}" | awk '{print $5}')
          COMPRESSED_SIZE=$(ls -lh "${BACKUP_FILE}.gz" | awk '{print $5}')
          echo "Original size: ${ORIGINAL_SIZE}"
          echo "Compressed size: ${COMPRESSED_SIZE}"
      
      - name: Backup R2 bucket metadata (READ ONLY)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "Starting R2 bucket metadata backup (READ ONLY operation)..."
          BACKUP_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)
          R2_BACKUP_DIR="backups/r2-${BACKUP_DATE}"
          mkdir -p "${R2_BACKUP_DIR}"
          
          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®URLãƒªã‚¹ãƒˆã‚’å–å¾—
          echo "Fetching file list from database..."
          wrangler d1 execute webapp-production --remote --command="SELECT id, application_type, attachment_url, created_at FROM applications WHERE attachment_url IS NOT NULL ORDER BY created_at DESC;" --json > "${R2_BACKUP_DIR}/file_list.json"
          
          # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã‚‚ä¿å­˜
          echo "Extracting file URLs..."
          cat "${R2_BACKUP_DIR}/file_list.json" | grep -o '"attachment_url"[^"]*"[^"]*"' | cut -d'"' -f4 | sort | uniq > "${R2_BACKUP_DIR}/file_urls.txt"
          
          # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
          FILE_COUNT=$(cat "${R2_BACKUP_DIR}/file_urls.txt" | wc -l)
          echo "Total files referenced in database: ${FILE_COUNT}"
          
          # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
          cat > "${R2_BACKUP_DIR}/README.md" << 'EOF'
# R2 Bucket Backup Metadata

This directory contains metadata about files stored in Cloudflare R2 bucket.

## Files

- `file_list.json`: Complete database records with attachment URLs
- `file_urls.txt`: List of all file URLs (one per line)
- `README.md`: This file

## Note

This backup contains file URLs and metadata only.
The actual image files are stored in Cloudflare R2 bucket: `webapp-receipts`

To backup actual files, you need to configure R2 S3-compatible API access.
See: https://developers.cloudflare.com/r2/api/s3/api/

## Cloudflare R2 Backup Protection

Cloudflare R2 has built-in durability (99.999999999% durability).
Your files are automatically replicated across multiple data centers.

For additional protection, consider:
1. Enable R2 versioning (preserves file history)
2. Use R2 lifecycle policies (archival)
3. Set up S3-compatible backup script with AWS CLI
EOF
          
          echo "R2 metadata backup completed"
          echo "Note: Actual file backup requires S3 API credentials (R2_ACCESS_KEY_ID and R2_SECRET_ACCESS_KEY)"
      
      - name: Compress R2 backup
        run: |
          BACKUP_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)
          R2_BACKUP_DIR="backups/r2-${BACKUP_DATE}"
          
          if [ -d "${R2_BACKUP_DIR}" ]; then
            tar -czf "${R2_BACKUP_DIR}.tar.gz" -C backups "r2-${BACKUP_DATE}"
            rm -rf "${R2_BACKUP_DIR}"
            
            R2_SIZE=$(ls -lh "${R2_BACKUP_DIR}.tar.gz" | awk '{print $5}')
            echo "R2 backup size: ${R2_SIZE}"
          else
            echo "R2 backup directory not found, skipping compression"
          fi
      
      - name: Commit and push backup
        run: |
          BACKUP_DATE=$(TZ=Asia/Tokyo date +%Y-%m-%d)
          
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add backups/
          
          # å¤‰æ›´ãŒã‚ã‚‹å ´åˆã®ã¿ã‚³ãƒŸãƒƒãƒˆ
          if git diff --staged --quiet; then
            echo "No changes to commit (backup file already exists)"
          else
            git commit -m "backup: Daily backup for ${BACKUP_DATE} (DB + R2)"
            git push
            echo "Backup committed and pushed to GitHub"
          fi
      
      - name: Backup summary
        if: always()
        run: |
          echo "================================================"
          echo "Database & R2 Backup Summary"
          echo "================================================"
          echo "Date: $(TZ=Asia/Tokyo date '+%Y-%m-%d %H:%M:%S JST')"
          echo "Database: webapp-production"
          echo "R2 Bucket: webapp-receipts"
          echo "Operation: READ ONLY (no data modified)"
          echo "Status: ${{ job.status }}"
          echo ""
          echo "Backup files:"
          ls -lh backups/ | tail -10
          echo ""
          echo "All backups are safely stored in GitHub"
          echo "================================================"
